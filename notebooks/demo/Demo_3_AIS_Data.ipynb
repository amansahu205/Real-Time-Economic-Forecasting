{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 3: AIS Maritime Data\n",
    "\n",
    "**Processing ship tracking data from NOAA**\n",
    "\n",
    "## What is AIS?\n",
    "- **Automatic Identification System** - GPS tracking for ships\n",
    "- Ships broadcast position, speed, heading, vessel type\n",
    "- NOAA collects and provides historical data\n",
    "\n",
    "## What We're Doing:\n",
    "- Load AIS data for Port of LA region\n",
    "- Extract ship counts and vessel types\n",
    "- Visualize maritime traffic patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Works both locally and in SageMaker\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Install dependencies in SageMaker\n",
    "IS_SAGEMAKER = os.path.exists('/home/ec2-user/SageMaker') or os.environ.get('SM_MODEL_DIR') is not None\n",
    "\n",
    "if IS_SAGEMAKER:\n",
    " print(' Installing dependencies...')\n",
    " import subprocess\n",
    " subprocess.run(['pip', 'install', 'ultralytics', 'opencv-python-headless', '-q'], check=True)\n",
    " print(' Dependencies installed')\n",
    "\n",
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# YOLO import\n",
    "try:\n",
    " from ultralytics import YOLO\n",
    " YOLO_AVAILABLE = True\n",
    "except ImportError:\n",
    " YOLO_AVAILABLE = False\n",
    " print(' YOLO not available - run: pip install ultralytics')\n",
    "\n",
    "# Environment detection\n",
    "if IS_SAGEMAKER:\n",
    " PROJECT_ROOT = Path('/home/ec2-user/SageMaker/Real-Time-Economic-Forecasting')\n",
    " USE_S3 = True\n",
    " print(' Running in AWS SageMaker')\n",
    "else:\n",
    " PROJECT_ROOT = Path.cwd().parent.parent\n",
    " USE_S3 = False\n",
    " print(' Running locally')\n",
    "\n",
    "# ===========================================\n",
    "# S3 BUCKET CONFIGURATION (ACTUAL STRUCTURE)\n",
    "# ===========================================\n",
    "S3_RAW = 'economic-forecast-raw'\n",
    "S3_MODELS = 'economic-forecast-models'\n",
    "S3_PROCESSED = 'economic-forecast-processed'\n",
    "\n",
    "# S3 Paths (matching actual bucket structure)\n",
    "S3_PATHS = {\n",
    " 'satellite': f's3://{S3_RAW}/satellite/google_earth',\n",
    " 'port_la_images': f's3://{S3_RAW}/satellite/google_earth/Port_of_LA',\n",
    " 'mall_images': f's3://{S3_RAW}/satellite/google_earth/Mall_of_america',\n",
    " 'models': f's3://{S3_MODELS}/yolo',\n",
    " 'port_model': f's3://{S3_MODELS}/yolo/ports/best.pt',\n",
    " 'retail_model': f's3://{S3_MODELS}/yolo/retail/best.pt',\n",
    " 'city_model': f's3://{S3_MODELS}/yolo/city/best.pt',\n",
    " 'ais': f's3://{S3_PROCESSED}/ais',\n",
    " 'ais_la': f's3://{S3_PROCESSED}/ais/Port_of_LA_ais_features.csv',\n",
    " 'detections': f's3://{S3_PROCESSED}/detections',\n",
    " 'news': f's3://{S3_RAW}/news/sentiment/data',\n",
    "}\n",
    "\n",
    "# Local paths\n",
    "LOCAL_PATHS = {\n",
    " 'satellite': PROJECT_ROOT / 'data' / 'raw' / 'satellite' / 'google_earth',\n",
    " 'port_la_images': PROJECT_ROOT / 'data' / 'raw' / 'satellite' / 'google_earth' / 'Port_of_LA',\n",
    " 'mall_images': PROJECT_ROOT / 'data' / 'raw' / 'satellite' / 'google_earth' / 'Mall_of_america',\n",
    " 'models': PROJECT_ROOT / 'data' / 'models' / 'satellite',\n",
    " 'port_model': PROJECT_ROOT / 'data' / 'models' / 'satellite' / 'ports_dota_yolo11_20251127_013205' / 'weights' / 'best.pt',\n",
    " 'retail_model': PROJECT_ROOT / 'data' / 'models' / 'satellite' / 'retail_yolo11_20251126_150811' / 'weights' / 'best.pt',\n",
    " 'ais': PROJECT_ROOT / 'data' / 'processed' / 'ais',\n",
    " 'ais_la': PROJECT_ROOT / 'data' / 'processed' / 'ais' / 'Port_of_LA_ais_features.csv',\n",
    " 'detections': PROJECT_ROOT / 'results' / 'annotations',\n",
    "}\n",
    "\n",
    "def get_path(key):\n",
    " '''Get path - S3 or local based on environment.'''\n",
    " if USE_S3:\n",
    "  return S3_PATHS.get(key, S3_PATHS.get('satellite'))\n",
    " else:\n",
    "  return LOCAL_PATHS.get(key, LOCAL_PATHS.get('satellite'))\n",
    "\n",
    "def download_model(model_type='port'):\n",
    " '''Download model from S3 to local temp for inference.'''\n",
    " if not USE_S3:\n",
    "  # Return local path\n",
    "  if model_type == 'port':\n",
    "   return LOCAL_PATHS['port_model']\n",
    "  elif model_type == 'retail':\n",
    "   return LOCAL_PATHS['retail_model']\n",
    "  return None\n",
    " \n",
    " import boto3\n",
    " import tempfile\n",
    " \n",
    " s3 = boto3.client('s3')\n",
    " \n",
    " model_keys = {\n",
    "  'port': 'yolo/ports/best.pt',\n",
    "  'retail': 'yolo/retail/best.pt',\n",
    "  'city': 'yolo/city/best.pt',\n",
    " }\n",
    " \n",
    " key = model_keys.get(model_type)\n",
    " if not key:\n",
    "  print(f' Unknown model type: {model_type}')\n",
    "  return None\n",
    " \n",
    " local_path = Path(tempfile.gettempdir()) / f'{model_type}_best.pt'\n",
    " \n",
    " if not local_path.exists():\n",
    "  print(f' Downloading {model_type} model from S3...')\n",
    "  s3.download_file(S3_MODELS, key, str(local_path))\n",
    "  print(f' Model saved to {local_path}')\n",
    " else:\n",
    "  print(f' Using cached model: {local_path}')\n",
    " \n",
    " return local_path\n",
    "\n",
    "def list_s3_images(prefix):\n",
    " '''List images in S3 bucket.'''\n",
    " import boto3\n",
    " s3 = boto3.client('s3')\n",
    " \n",
    " # Parse bucket and prefix from s3:// path\n",
    " if prefix.startswith('s3://'):\n",
    "  parts = prefix.replace('s3://', '').split('/', 1)\n",
    "  bucket = parts[0]\n",
    "  prefix = parts[1] if len(parts) > 1 else ''\n",
    " else:\n",
    "  bucket = S3_RAW\n",
    " \n",
    " response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    " \n",
    " images = []\n",
    " for obj in response.get('Contents', []):\n",
    "  key = obj['Key']\n",
    "  if key.endswith(('.jpg', '.jpeg', '.png', '.tif')):\n",
    "   images.append(f's3://{bucket}/{key}')\n",
    " \n",
    " return images\n",
    "\n",
    "def download_image(s3_path, local_dir='/tmp'):\n",
    " '''Download single image from S3.'''\n",
    " import boto3\n",
    " s3 = boto3.client('s3')\n",
    " \n",
    " parts = s3_path.replace('s3://', '').split('/', 1)\n",
    " bucket = parts[0]\n",
    " key = parts[1]\n",
    " \n",
    " filename = key.split('/')[-1]\n",
    " local_path = Path(local_dir) / filename\n",
    " \n",
    " s3.download_file(bucket, key, str(local_path))\n",
    " return local_path\n",
    "\n",
    "print(f' Setup complete | S3: {USE_S3} | YOLO: {YOLO_AVAILABLE}')\n",
    "print(f' Project: {PROJECT_ROOT}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Understanding AIS Data\n",
    "\n",
    "```\n",
    "Ship broadcasts every few seconds:\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502 MMSI: 123456789 (unique ship ID)    \u2502\n",
    "\u2502 LAT: 33.7234, LON: -118.2654     \u2502\n",
    "\u2502 SOG: 12.5 knots (speed over ground)    \u2502\n",
    "\u2502 COG: 275\u00b0 (course over ground)     \u2502\n",
    "\u2502 VesselType: 70 (cargo ship)      \u2502\n",
    "\u2502 VesselName: \"EVER GIVEN\"      \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIS Vessel Type Codes\n",
    "print(\"\ud83d\udccb AIS VESSEL TYPE CODES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "vessel_types = {\n",
    " '70-79': 'Cargo vessels',\n",
    " '80-89': 'Tankers',\n",
    " '60-69': 'Passenger vessels',\n",
    " '30': 'Fishing vessels',\n",
    " '31-32': 'Tug boats',\n",
    " '36-37': 'Sailing vessels',\n",
    "}\n",
    "\n",
    "for code, desc in vessel_types.items():\n",
    " print(f\" {code}: {desc}\")\n",
    "\n",
    "print(\"\\n Cargo (70-79) and Tankers (80-89) are key economic indicators!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load AIS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available AIS data\n",
    "ais_dir = PROJECT_ROOT / 'data' / 'raw' / 'ais' / 'noaa_daily'\n",
    "\n",
    "print(\" AVAILABLE AIS DATA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if ais_dir.exists():\n",
    " for year_dir in sorted(ais_dir.iterdir()):\n",
    "  if year_dir.is_dir():\n",
    "   files = list(year_dir.glob('*.zip'))\n",
    "   if files:\n",
    "    total_size = sum(f.stat().st_size for f in files) / (1024*1024)\n",
    "    print(f\" {year_dir.name}: {len(files)} files ({total_size:.1f} MB)\")\n",
    "else:\n",
    " print(\" AIS data directory not found\")\n",
    " print(\" Creating sample data for demo...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Port of LA bounding box\n",
    "PORT_LA_BOUNDS = {\n",
    " 'min_lat': 33.65,\n",
    " 'max_lat': 33.85,\n",
    " 'min_lon': -118.35,\n",
    " 'max_lon': -118.15\n",
    "}\n",
    "\n",
    "print(\"\ud83d\udccd PORT OF LA BOUNDING BOX\")\n",
    "print(\"=\"*50)\n",
    "print(f\" Latitude: {PORT_LA_BOUNDS['min_lat']}\u00b0 to {PORT_LA_BOUNDS['max_lat']}\u00b0\")\n",
    "print(f\" Longitude: {PORT_LA_BOUNDS['min_lon']}\u00b0 to {PORT_LA_BOUNDS['max_lon']}\u00b0\")\n",
    "\n",
    "# Visualize on a simple map\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Draw bounding box\n",
    "from matplotlib.patches import Rectangle\n",
    "rect = Rectangle(\n",
    " (PORT_LA_BOUNDS['min_lon'], PORT_LA_BOUNDS['min_lat']),\n",
    " PORT_LA_BOUNDS['max_lon'] - PORT_LA_BOUNDS['min_lon'],\n",
    " PORT_LA_BOUNDS['max_lat'] - PORT_LA_BOUNDS['min_lat'],\n",
    " fill=True, facecolor='lightblue', edgecolor='blue', linewidth=2, alpha=0.5\n",
    ")\n",
    "ax.add_patch(rect)\n",
    "\n",
    "# Add port marker\n",
    "ax.plot(-118.25, 33.75, 'r*', markersize=20, label='Port of LA')\n",
    "\n",
    "ax.set_xlim(-118.5, -118.0)\n",
    "ax.set_ylim(33.5, 34.0)\n",
    "ax.set_xlabel('Longitude', fontsize=12)\n",
    "ax.set_ylabel('Latitude', fontsize=12)\n",
    "ax.set_title('\ud83d\uddfa\ufe0f Port of LA - AIS Capture Area', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Process AIS Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load real AIS data, or create sample\n",
    "def load_ais_sample():\n",
    " \"\"\"Load AIS data from zip file or create sample.\"\"\"\n",
    " \n",
    " # Check for real data\n",
    " ais_files = list((PROJECT_ROOT / 'data' / 'raw' / 'ais' / 'noaa_daily').rglob('*.zip'))\n",
    " \n",
    " if ais_files:\n",
    "  # Load first available file\n",
    "  zip_path = ais_files[0]\n",
    "  print(f\" Loading: {zip_path.name}\")\n",
    "  \n",
    "  with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "   csv_name = [f for f in z.namelist() if f.endswith('.csv')][0]\n",
    "   with z.open(csv_name) as f:\n",
    "    df = pd.read_csv(f, nrows=100000) # Sample for speed\n",
    "  \n",
    "  # Filter to Port of LA area\n",
    "  df_filtered = df[\n",
    "   (df['LAT'] >= PORT_LA_BOUNDS['min_lat']) &\n",
    "   (df['LAT'] <= PORT_LA_BOUNDS['max_lat']) &\n",
    "   (df['LON'] >= PORT_LA_BOUNDS['min_lon']) &\n",
    "   (df['LON'] <= PORT_LA_BOUNDS['max_lon'])\n",
    "  ]\n",
    "  \n",
    "  if len(df_filtered) > 0:\n",
    "   return df_filtered\n",
    " \n",
    " # Create sample data for demo\n",
    " print(\" Creating sample AIS data for demo...\")\n",
    " np.random.seed(42)\n",
    " n_records = 5000\n",
    " \n",
    " sample_df = pd.DataFrame({\n",
    "  'MMSI': np.random.randint(100000000, 999999999, n_records),\n",
    "  'BaseDateTime': pd.date_range('2024-06-15', periods=n_records, freq='1min'),\n",
    "  'LAT': np.random.uniform(33.65, 33.85, n_records),\n",
    "  'LON': np.random.uniform(-118.35, -118.15, n_records),\n",
    "  'SOG': np.random.uniform(0, 15, n_records),\n",
    "  'COG': np.random.uniform(0, 360, n_records),\n",
    "  'VesselType': np.random.choice([70, 71, 72, 80, 81, 60, 30, 31], n_records, \n",
    "          p=[0.3, 0.15, 0.1, 0.15, 0.1, 0.05, 0.1, 0.05]),\n",
    "  'VesselName': [f'VESSEL_{i}' for i in range(n_records)]\n",
    " })\n",
    " \n",
    " return sample_df\n",
    "\n",
    "ais_df = load_ais_sample()\n",
    "print(f\"\\n Loaded {len(ais_df):,} AIS records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample of AIS data\n",
    "print(\" AIS DATA SAMPLE\")\n",
    "print(\"=\"*60)\n",
    "display(ais_df[['MMSI', 'BaseDateTime', 'LAT', 'LON', 'SOG', 'VesselType']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Analyze Ship Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify vessel types\n",
    "def classify_vessel(code):\n",
    " try:\n",
    "  code = int(code)\n",
    "  if 70 <= code < 80:\n",
    "   return 'Cargo'\n",
    "  elif 80 <= code < 90:\n",
    "   return 'Tanker'\n",
    "  elif 60 <= code < 70:\n",
    "   return 'Passenger'\n",
    "  elif code == 30:\n",
    "   return 'Fishing'\n",
    "  elif code in [31, 32, 52]:\n",
    "   return 'Tug'\n",
    "  else:\n",
    "   return 'Other'\n",
    " except:\n",
    "  return 'Unknown'\n",
    "\n",
    "ais_df['vessel_category'] = ais_df['VesselType'].apply(classify_vessel)\n",
    "\n",
    "# Count unique ships by category\n",
    "ship_counts = ais_df.groupby('vessel_category')['MMSI'].nunique().sort_values(ascending=False)\n",
    "\n",
    "print(\" UNIQUE SHIPS BY CATEGORY\")\n",
    "print(\"=\"*50)\n",
    "for cat, count in ship_counts.items():\n",
    " print(f\" {cat}: {count} ships\")\n",
    "\n",
    "print(f\"\\n TOTAL: {ais_df['MMSI'].nunique()} unique ships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize vessel distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart of vessel types\n",
    "ax1 = axes[0]\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c', '#f39c12', '#9b59b6', '#95a5a6']\n",
    "ax1.pie(ship_counts.values, labels=ship_counts.index, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "ax1.set_title(' Vessel Type Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar chart\n",
    "ax2 = axes[1]\n",
    "bars = ax2.bar(ship_counts.index, ship_counts.values, color=colors, edgecolor='black')\n",
    "ax2.set_xlabel('Vessel Type', fontsize=12)\n",
    "ax2.set_ylabel('Number of Ships', fontsize=12)\n",
    "ax2.set_title(' Ships by Category', fontsize=14, fontweight='bold')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, ship_counts.values):\n",
    " ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, str(val), \n",
    "    ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ship Positions Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ship positions\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Color by vessel type\n",
    "color_map = {\n",
    " 'Cargo': 'green',\n",
    " 'Tanker': 'blue',\n",
    " 'Passenger': 'red',\n",
    " 'Fishing': 'orange',\n",
    " 'Tug': 'purple',\n",
    " 'Other': 'gray',\n",
    " 'Unknown': 'lightgray'\n",
    "}\n",
    "\n",
    "for cat, color in color_map.items():\n",
    " subset = ais_df[ais_df['vessel_category'] == cat]\n",
    " if len(subset) > 0:\n",
    "  ax.scatter(subset['LON'], subset['LAT'], c=color, label=cat, alpha=0.5, s=10)\n",
    "\n",
    "# Add port marker\n",
    "ax.plot(-118.25, 33.75, 'r*', markersize=25, label='Port Center', zorder=10)\n",
    "\n",
    "ax.set_xlabel('Longitude', fontsize=12)\n",
    "ax.set_ylabel('Latitude', fontsize=12)\n",
    "ax.set_title('\ud83d\uddfa\ufe0f Ship Positions at Port of LA', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Economic Metrics from AIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate economic indicators\n",
    "print(\" ECONOMIC INDICATORS FROM AIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_ships = ais_df['MMSI'].nunique()\n",
    "cargo_ships = ais_df[ais_df['vessel_category'] == 'Cargo']['MMSI'].nunique()\n",
    "tanker_ships = ais_df[ais_df['vessel_category'] == 'Tanker']['MMSI'].nunique()\n",
    "\n",
    "# Economic indicators\n",
    "cargo_ratio = cargo_ships / total_ships * 100\n",
    "trade_activity_index = (cargo_ships + tanker_ships) / total_ships * 100\n",
    "\n",
    "print(f\"\\n Key Metrics:\")\n",
    "print(f\" \u2022 Total unique ships: {total_ships}\")\n",
    "print(f\" \u2022 Cargo ships: {cargo_ships} ({cargo_ratio:.1f}%)\")\n",
    "print(f\" \u2022 Tanker ships: {tanker_ships}\")\n",
    "print(f\" \u2022 Trade Activity Index: {trade_activity_index:.1f}%\")\n",
    "\n",
    "print(f\"\\n INSIGHT:\")\n",
    "print(f\" High cargo ratio ({cargo_ratio:.0f}%) indicates strong trade activity!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### What We Learned:\n",
    "1. **AIS** provides real-time ship tracking data\n",
    "2. **Vessel types** indicate economic activity (cargo = trade)\n",
    "3. **Ship counts** correlate with port throughput\n",
    "4. **Daily data** enables high-frequency economic monitoring\n",
    "\n",
    "### Key Metrics Extracted:\n",
    "- Total ships in port area\n",
    "- Cargo vs tanker ratio\n",
    "- Trade activity index\n",
    "\n",
    "### Next Step:\n",
    "\u2192 **Demo 4**: Fuse satellite detections with AIS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\" Demo 3 Complete: AIS Data Processing\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n Next: Demo_4_Data_Fusion.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}