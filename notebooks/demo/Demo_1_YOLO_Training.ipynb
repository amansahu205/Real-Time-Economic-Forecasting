{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 1: YOLO Model Fine-Tuning\n",
    "\n",
    "**Training object detection models for satellite imagery**\n",
    "\n",
    "## What We're Doing:\n",
    "- Fine-tune YOLO11 on satellite imagery\n",
    "- Train for ship detection (ports) and vehicle detection (retail)\n",
    "- Quick demo: 4-5 iterations to show the process\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Works both locally and in SageMaker\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Install dependencies in SageMaker\n",
    "IS_SAGEMAKER = os.path.exists('/home/ec2-user/SageMaker') or os.environ.get('SM_MODEL_DIR') is not None\n",
    "\n",
    "if IS_SAGEMAKER:\n",
    " print(' Installing dependencies...')\n",
    " import subprocess\n",
    " subprocess.run(['pip', 'install', 'ultralytics', 'opencv-python-headless', '-q'], check=True)\n",
    " print(' Dependencies installed')\n",
    "\n",
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# YOLO import\n",
    "try:\n",
    " from ultralytics import YOLO\n",
    " YOLO_AVAILABLE = True\n",
    "except ImportError:\n",
    " YOLO_AVAILABLE = False\n",
    " print(' YOLO not available - run: pip install ultralytics')\n",
    "\n",
    "# Environment detection\n",
    "if IS_SAGEMAKER:\n",
    " PROJECT_ROOT = Path('/home/ec2-user/SageMaker/Real-Time-Economic-Forecasting')\n",
    " USE_S3 = True\n",
    " print(' Running in AWS SageMaker')\n",
    "else:\n",
    " PROJECT_ROOT = Path.cwd().parent.parent\n",
    " USE_S3 = False\n",
    " print(' Running locally')\n",
    "\n",
    "# ===========================================\n",
    "# S3 BUCKET CONFIGURATION (ACTUAL STRUCTURE)\n",
    "# ===========================================\n",
    "S3_RAW = 'economic-forecast-raw'\n",
    "S3_MODELS = 'economic-forecast-models'\n",
    "S3_PROCESSED = 'economic-forecast-processed'\n",
    "\n",
    "# S3 Paths (matching actual bucket structure)\n",
    "S3_PATHS = {\n",
    " 'satellite': f's3://{S3_RAW}/satellite/google_earth',\n",
    " 'port_la_images': f's3://{S3_RAW}/satellite/google_earth/Port_of_LA',\n",
    " 'mall_images': f's3://{S3_RAW}/satellite/google_earth/Mall_of_america',\n",
    " 'models': f's3://{S3_MODELS}/yolo',\n",
    " 'port_model': f's3://{S3_MODELS}/yolo/ports/best.pt',\n",
    " 'retail_model': f's3://{S3_MODELS}/yolo/retail/best.pt',\n",
    " 'city_model': f's3://{S3_MODELS}/yolo/city/best.pt',\n",
    " 'ais': f's3://{S3_PROCESSED}/ais',\n",
    " 'ais_la': f's3://{S3_PROCESSED}/ais/Port_of_LA_ais_features.csv',\n",
    " 'detections': f's3://{S3_PROCESSED}/detections',\n",
    " 'news': f's3://{S3_RAW}/news/sentiment/data',\n",
    "}\n",
    "\n",
    "# Local paths\n",
    "LOCAL_PATHS = {\n",
    " 'satellite': PROJECT_ROOT / 'data' / 'raw' / 'satellite' / 'google_earth',\n",
    " 'port_la_images': PROJECT_ROOT / 'data' / 'raw' / 'satellite' / 'google_earth' / 'Port_of_LA',\n",
    " 'mall_images': PROJECT_ROOT / 'data' / 'raw' / 'satellite' / 'google_earth' / 'Mall_of_america',\n",
    " 'models': PROJECT_ROOT / 'data' / 'models' / 'satellite',\n",
    " 'port_model': PROJECT_ROOT / 'data' / 'models' / 'satellite' / 'ports_dota_yolo11_20251127_013205' / 'weights' / 'best.pt',\n",
    " 'retail_model': PROJECT_ROOT / 'data' / 'models' / 'satellite' / 'retail_yolo11_20251126_150811' / 'weights' / 'best.pt',\n",
    " 'ais': PROJECT_ROOT / 'data' / 'processed' / 'ais',\n",
    " 'ais_la': PROJECT_ROOT / 'data' / 'processed' / 'ais' / 'Port_of_LA_ais_features.csv',\n",
    " 'detections': PROJECT_ROOT / 'results' / 'annotations',\n",
    "}\n",
    "\n",
    "def get_path(key):\n",
    " '''Get path - S3 or local based on environment.'''\n",
    " if USE_S3:\n",
    "  return S3_PATHS.get(key, S3_PATHS.get('satellite'))\n",
    " else:\n",
    "  return LOCAL_PATHS.get(key, LOCAL_PATHS.get('satellite'))\n",
    "\n",
    "def download_model(model_type='port'):\n",
    " '''Download model from S3 to local temp for inference.'''\n",
    " if not USE_S3:\n",
    "  # Return local path\n",
    "  if model_type == 'port':\n",
    "   return LOCAL_PATHS['port_model']\n",
    "  elif model_type == 'retail':\n",
    "   return LOCAL_PATHS['retail_model']\n",
    "  return None\n",
    " \n",
    " import boto3\n",
    " import tempfile\n",
    " \n",
    " s3 = boto3.client('s3')\n",
    " \n",
    " model_keys = {\n",
    "  'port': 'yolo/ports/best.pt',\n",
    "  'retail': 'yolo/retail/best.pt',\n",
    "  'city': 'yolo/city/best.pt',\n",
    " }\n",
    " \n",
    " key = model_keys.get(model_type)\n",
    " if not key:\n",
    "  print(f' Unknown model type: {model_type}')\n",
    "  return None\n",
    " \n",
    " local_path = Path(tempfile.gettempdir()) / f'{model_type}_best.pt'\n",
    " \n",
    " if not local_path.exists():\n",
    "  print(f' Downloading {model_type} model from S3...')\n",
    "  s3.download_file(S3_MODELS, key, str(local_path))\n",
    "  print(f' Model saved to {local_path}')\n",
    " else:\n",
    "  print(f' Using cached model: {local_path}')\n",
    " \n",
    " return local_path\n",
    "\n",
    "def list_s3_images(prefix):\n",
    " '''List images in S3 bucket.'''\n",
    " import boto3\n",
    " s3 = boto3.client('s3')\n",
    " \n",
    " # Parse bucket and prefix from s3:// path\n",
    " if prefix.startswith('s3://'):\n",
    "  parts = prefix.replace('s3://', '').split('/', 1)\n",
    "  bucket = parts[0]\n",
    "  prefix = parts[1] if len(parts) > 1 else ''\n",
    " else:\n",
    "  bucket = S3_RAW\n",
    " \n",
    " response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    " \n",
    " images = []\n",
    " for obj in response.get('Contents', []):\n",
    "  key = obj['Key']\n",
    "  if key.endswith(('.jpg', '.jpeg', '.png', '.tif')):\n",
    "   images.append(f's3://{bucket}/{key}')\n",
    " \n",
    " return images\n",
    "\n",
    "def download_image(s3_path, local_dir='/tmp'):\n",
    " '''Download single image from S3.'''\n",
    " import boto3\n",
    " s3 = boto3.client('s3')\n",
    " \n",
    " parts = s3_path.replace('s3://', '').split('/', 1)\n",
    " bucket = parts[0]\n",
    " key = parts[1]\n",
    " \n",
    " filename = key.split('/')[-1]\n",
    " local_path = Path(local_dir) / filename\n",
    " \n",
    " s3.download_file(bucket, key, str(local_path))\n",
    " return local_path\n",
    "\n",
    "print(f' Setup complete | S3: {USE_S3} | YOLO: {YOLO_AVAILABLE}')\n",
    "print(f' Project: {PROJECT_ROOT}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Understanding YOLO Architecture\n",
    "\n",
    "**YOLO (You Only Look Once)** - Real-time object detection\n",
    "\n",
    "```\n",
    "Input Image → Backbone (Feature Extraction) → Neck → Head → Detections\n",
    "               ↓\n",
    "            [class, x, y, w, h, conf]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained YOLO11 model\n",
    "print(\" Loading YOLO11 base model...\")\n",
    "model = YOLO('yolo11n.pt') # nano version for fast demo\n",
    "\n",
    "print(\"\\n Model Architecture:\")\n",
    "print(f\" • Model: YOLO11-nano\")\n",
    "print(f\" • Parameters: ~2.6M\")\n",
    "print(f\" • Pre-trained on: COCO dataset (80 classes)\")\n",
    "print(f\" • Our task: Fine-tune for satellite imagery\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training Datasets\n",
    "\n",
    "We use two specialized datasets:\n",
    "\n",
    "| Dataset | Purpose | Classes |\n",
    "|---------|---------|--------|\n",
    "| **DOTA** | Aerial/satellite objects | ship, harbor, storage-tank, vehicle |\n",
    "| **xView** | Overhead imagery | ships, vehicles, buildings |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dataset structure\n",
    "print(\" TRAINING DATA STRUCTURE\")\n",
    "print(\"=\"*50)\n",
    "print(\"\"\"\n",
    "data/models/\n",
    "├── satellite/   # Port detection model\n",
    "│ ├── train/\n",
    "│ │ ├── images/  # Satellite images\n",
    "│ │ └── labels/  # YOLO format annotations\n",
    "│ └── valid/\n",
    "│\n",
    "└── retail/    # Vehicle detection model \n",
    " ├── train/\n",
    " │ ├── images/  # Parking lot images\n",
    " │ └── labels/  # Car annotations\n",
    " └── valid/\n",
    "\n",
    "Label Format (YOLO):\n",
    " class_id x_center y_center width height\n",
    " 0   0.45  0.32  0.12 0.08\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Fine-Tuning Demo (Quick Training)\n",
    "\n",
    " **For demo purposes**: Training only 5 epochs\n",
    "\n",
    "In production, we trained for 100+ epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a minimal dataset config for demo\n",
    "demo_yaml = \"\"\"\n",
    "# Demo training config\n",
    "path: ../data/models/satellite\n",
    "train: train/images\n",
    "val: valid/images\n",
    "\n",
    "names:\n",
    " 0: ship\n",
    " 1: storage-tank\n",
    " 2: harbor\n",
    " 3: large-vehicle\n",
    " 4: small-vehicle\n",
    "\"\"\"\n",
    "\n",
    "print(\" Dataset Configuration:\")\n",
    "print(demo_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO: Train for just 2 epochs to show the process\n",
    "# NOTE: In production, we trained for 100+ epochs\n",
    "\n",
    "print(\" STARTING DEMO TRAINING\")\n",
    "print(\"=\"*50)\n",
    "print(\" Demo mode: 2 epochs only (production: 100+)\")\n",
    "print()\n",
    "\n",
    "# Check if training data exists\n",
    "train_path = PROJECT_ROOT / 'data' / 'models' / 'satellite' / 'train' / 'images'\n",
    "\n",
    "if train_path.exists() and len(list(train_path.glob('*'))) > 0:\n",
    " # Actual training demo\n",
    " model = YOLO('yolo11n.pt')\n",
    " results = model.train(\n",
    "  data=str(PROJECT_ROOT / 'data' / 'models' / 'satellite' / 'data.yaml'),\n",
    "  epochs=2,   # Just 2 for demo\n",
    "  imgsz=640,\n",
    "  batch=4,\n",
    "  device='cpu',  # Use CPU for compatibility\n",
    "  verbose=True,\n",
    "  project=str(PROJECT_ROOT / 'runs' / 'demo'),\n",
    "  name='satellite_demo'\n",
    " )\n",
    " print(\"\\n Demo training complete!\")\n",
    "else:\n",
    " # Simulated training output\n",
    " print(\" Simulated Training Progress:\")\n",
    " print()\n",
    " epochs_demo = [\n",
    "  {'epoch': 1, 'loss': 2.45, 'mAP50': 0.12},\n",
    "  {'epoch': 2, 'loss': 1.89, 'mAP50': 0.28},\n",
    "  {'epoch': 3, 'loss': 1.52, 'mAP50': 0.45},\n",
    "  {'epoch': 4, 'loss': 1.21, 'mAP50': 0.58},\n",
    "  {'epoch': 5, 'loss': 0.98, 'mAP50': 0.67},\n",
    " ]\n",
    " \n",
    " for e in epochs_demo:\n",
    "  print(f\" Epoch {e['epoch']}/5: loss={e['loss']:.3f}, mAP50={e['mAP50']:.3f}\")\n",
    " \n",
    " print(\"\\n Demo training simulation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ACTUAL training metrics from our trained models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load actual training results\n",
    "port_results_path = PROJECT_ROOT / 'data' / 'models' / 'satellite' / 'ports_dota_yolo11_20251127_013205' / 'results.csv'\n",
    "retail_results_path = PROJECT_ROOT / 'data' / 'models' / 'satellite' / 'retail_yolo11_20251126_150811' / 'results.csv'\n",
    "\n",
    "# Read actual metrics\n",
    "if port_results_path.exists():\n",
    "    port_df = pd.read_csv(port_results_path)\n",
    "    port_df.columns = port_df.columns.str.strip()\n",
    "    print(\"Loaded Port Detection training metrics\")\n",
    "else:\n",
    "    print(\"Port results not found, using sample data\")\n",
    "    port_df = None\n",
    "\n",
    "if retail_results_path.exists():\n",
    "    retail_df = pd.read_csv(retail_results_path)\n",
    "    retail_df.columns = retail_df.columns.str.strip()\n",
    "    print(\"Loaded Retail Detection training metrics\")\n",
    "else:\n",
    "    retail_df = None\n",
    "\n",
    "# Plot actual training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Port Model - Loss\n",
    "ax1 = axes[0, 0]\n",
    "if port_df is not None:\n",
    "    ax1.plot(port_df['epoch'], port_df['train/box_loss'], 'b-', linewidth=2, label='Box Loss')\n",
    "    ax1.plot(port_df['epoch'], port_df['train/cls_loss'], 'r-', linewidth=1.5, alpha=0.7, label='Class Loss')\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Port Detection - Training Loss', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Port Model - mAP\n",
    "ax2 = axes[0, 1]\n",
    "if port_df is not None:\n",
    "    ax2.plot(port_df['epoch'], port_df['metrics/mAP50(B)'] * 100, 'g-', linewidth=2, label='mAP@50')\n",
    "    ax2.plot(port_df['epoch'], port_df['metrics/mAP50-95(B)'] * 100, 'b-', linewidth=1.5, alpha=0.7, label='mAP@50-95')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('mAP (%)', fontsize=12)\n",
    "ax2.set_title('Port Detection - Accuracy (mAP)', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=70, color='r', linestyle='--', alpha=0.5, label='Target (70%)')\n",
    "ax2.legend()\n",
    "\n",
    "# Retail Model - Loss\n",
    "ax3 = axes[1, 0]\n",
    "if retail_df is not None:\n",
    "    ax3.plot(retail_df['epoch'], retail_df['train/box_loss'], 'b-', linewidth=2, label='Box Loss')\n",
    "    ax3.plot(retail_df['epoch'], retail_df['train/cls_loss'], 'r-', linewidth=1.5, alpha=0.7, label='Class Loss')\n",
    "ax3.set_xlabel('Epoch', fontsize=12)\n",
    "ax3.set_ylabel('Loss', fontsize=12)\n",
    "ax3.set_title('Retail Detection - Training Loss', fontsize=14, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.legend()\n",
    "\n",
    "# Retail Model - mAP\n",
    "ax4 = axes[1, 1]\n",
    "if retail_df is not None:\n",
    "    ax4.plot(retail_df['epoch'], retail_df['metrics/mAP50(B)'] * 100, 'g-', linewidth=2, label='mAP@50')\n",
    "    ax4.plot(retail_df['epoch'], retail_df['metrics/mAP50-95(B)'] * 100, 'b-', linewidth=1.5, alpha=0.7, label='mAP@50-95')\n",
    "ax4.set_xlabel('Epoch', fontsize=12)\n",
    "ax4.set_ylabel('mAP (%)', fontsize=12)\n",
    "ax4.set_title('Retail Detection - Accuracy (mAP)', fontsize=14, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ACTUAL TRAINING RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if port_df is not None:\n",
    "    print(f\"\\nPort Detection Model (120 epochs):\")\n",
    "    print(f\"  Final mAP@50:    {port_df['metrics/mAP50(B)'].iloc[-1]*100:.1f}%\")\n",
    "    print(f\"  Final mAP@50-95: {port_df['metrics/mAP50-95(B)'].iloc[-1]*100:.1f}%\")\n",
    "    print(f\"  Final Precision: {port_df['metrics/precision(B)'].iloc[-1]*100:.1f}%\")\n",
    "    print(f\"  Final Recall:    {port_df['metrics/recall(B)'].iloc[-1]*100:.1f}%\")\n",
    "\n",
    "if retail_df is not None:\n",
    "    print(f\"\\nRetail Detection Model (94 epochs):\")\n",
    "    print(f\"  Final mAP@50:    {retail_df['metrics/mAP50(B)'].iloc[-1]*100:.1f}%\")\n",
    "    print(f\"  Final mAP@50-95: {retail_df['metrics/mAP50-95(B)'].iloc[-1]*100:.1f}%\")\n",
    "    print(f\"  Final Precision: {retail_df['metrics/precision(B)'].iloc[-1]*100:.1f}%\")\n",
    "    print(f\"  Final Recall:    {retail_df['metrics/recall(B)'].iloc[-1]*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Our Trained Models\n",
    "\n",
    "We have 3 fine-tuned models ready:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show our ACTUAL trained models with real metrics\n",
    "print(\"TRAINED MODELS - ACTUAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "models_info = [\n",
    "    {\n",
    "        'name': 'Port Detection (DOTA)',\n",
    "        'file': 'ports_dota_yolo11_20251127_013205/weights/best.pt',\n",
    "        'classes': ['ship', 'storage-tank', 'harbor', 'large-vehicle', 'small-vehicle'],\n",
    "        'epochs': 120,\n",
    "        'mAP50': 71.5,\n",
    "        'mAP50_95': 46.6,\n",
    "        'precision': 80.2,\n",
    "        'recall': 67.5,\n",
    "        'training_time': '17 hours',\n",
    "        'use': 'Port of LA satellite images'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Retail Detection',\n",
    "        'file': 'retail_yolo11_20251126_150811/weights/best.pt',\n",
    "        'classes': ['car', 'truck', 'bus'],\n",
    "        'epochs': 94,\n",
    "        'mAP50': 41.5,\n",
    "        'mAP50_95': 17.7,\n",
    "        'precision': 39.6,\n",
    "        'recall': 55.7,\n",
    "        'training_time': '3 hours',\n",
    "        'use': 'Mall of America parking lots'\n",
    "    },\n",
    "    {\n",
    "        'name': 'City Detection',\n",
    "        'file': 'city_yolo11_20251127_184743/weights/best.pt',\n",
    "        'classes': ['building', 'vehicle', 'road'],\n",
    "        'epochs': 84,\n",
    "        'mAP50': 29.1,\n",
    "        'mAP50_95': 13.0,\n",
    "        'precision': 32.9,\n",
    "        'recall': 36.1,\n",
    "        'training_time': '6 hours',\n",
    "        'use': 'Urban area detection'\n",
    "    }\n",
    "]\n",
    "\n",
    "for m in models_info:\n",
    "    print(f\"\\n{m['name']}\")\n",
    "    print(f\"  File: {m['file']}\")\n",
    "    print(f\"  Classes: {', '.join(m['classes'])}\")\n",
    "    print(f\"  Epochs: {m['epochs']}\")\n",
    "    print(f\"  mAP@50: {m['mAP50']:.1f}%\")\n",
    "    print(f\"  mAP@50-95: {m['mAP50_95']:.1f}%\")\n",
    "    print(f\"  Precision: {m['precision']:.1f}%\")\n",
    "    print(f\"  Recall: {m['recall']:.1f}%\")\n",
    "    print(f\"  Training Time: {m['training_time']}\")\n",
    "    print(f\"  Use: {m['use']}\")\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Model':<20} {'mAP@50':>10} {'mAP@50-95':>12} {'Precision':>12} {'Recall':>10}\")\n",
    "print(\"-\"*60)\n",
    "for m in models_info:\n",
    "    print(f\"{m['name']:<20} {m['mAP50']:>9.1f}% {m['mAP50_95']:>11.1f}% {m['precision']:>11.1f}% {m['recall']:>9.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Training Results:\n",
    "| Model | mAP@50 | Epochs | Training Time |\n",
    "|-------|--------|--------|---------------|\n",
    "| **Port Detection** | 71.5% | 120 | 17 hours |\n",
    "| **Retail Detection** | 41.5% | 94 | 3 hours |\n",
    "| **City Detection** | 29.1% | 84 | 6 hours |\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **Port Detection** achieves best accuracy (71.5% mAP) - ideal for ship counting\n",
    "2. **YOLO11** fine-tuned on DOTA dataset for satellite imagery\n",
    "3. **Tiled detection** handles high-resolution images (8000x5000 pixels)\n",
    "4. Models stored in S3 for AWS Lambda inference\n",
    "\n",
    "### Next Step:\n",
    "**Demo 2**: Use these models to detect objects in satellite images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\" Demo 1 Complete: YOLO Fine-Tuning\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n Next: Demo_2_Object_Detection.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
