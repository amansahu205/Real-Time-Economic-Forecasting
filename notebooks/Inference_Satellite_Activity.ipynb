{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõ∞Ô∏è Satellite Imagery Inference - Economic Activity Extraction\n",
    "\n",
    "Extract economic activity metrics from satellite imagery using trained YOLO models.\n",
    "\n",
    "## Purpose:\n",
    "Transform satellite imagery ‚Üí Activity metrics for economic forecasting\n",
    "\n",
    "## Models Used:\n",
    "- **Retail**: Car counting (41.5% mAP)\n",
    "- **Ports**: Ship/vehicle/harbor detection (72.0% mAP)  \n",
    "- **City**: Vehicle density (training)\n",
    "\n",
    "## Outputs:\n",
    "- `data/features/satellite/retail_activity.csv`\n",
    "- `data/features/satellite/port_activity.csv`\n",
    "- `data/features/satellite/city_activity.csv`\n",
    "- `data/features/satellite/industrial_activity.csv`\n",
    "\n",
    "## Time Required:\n",
    "**2-4 hours** (depends on GPU)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Imports successful\")\n",
    "print(f\"üìÖ Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RAW_SATELLITE = DATA_DIR / \"raw\" / \"satellite\"\n",
    "FEATURES_DIR = DATA_DIR / \"features\" / \"satellite\"\n",
    "MODELS_DIR = DATA_DIR / \"models\" / \"satellite\"\n",
    "\n",
    "# Create output directory\n",
    "FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Model paths\n",
    "MODELS = {\n",
    "    'retail': MODELS_DIR / \"retail_yolo11_20251126_150811\" / \"weights\" / \"best.pt\",\n",
    "    'ports': MODELS_DIR / \"ports_dota_yolo11_20251127_013205\" / \"weights\" / \"best.pt\",\n",
    "    'city': MODELS_DIR / \"city_yolo11_20251127_184743\" / \"weights\" / \"best.pt\",\n",
    "}\n",
    "\n",
    "# Class names for each model\n",
    "CLASS_NAMES = {\n",
    "    'retail': ['car', 'equipment'],\n",
    "    'ports': ['ship', 'harbor', 'large-vehicle', 'small-vehicle', 'storage-tank'],\n",
    "    'city': ['car', 'truck', 'warehouse'],\n",
    "}\n",
    "\n",
    "# Years to process\n",
    "YEARS = [2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
    "\n",
    "# Inference settings\n",
    "INFERENCE_CONFIG = {\n",
    "    'conf': 0.25,  # Confidence threshold\n",
    "    'iou': 0.45,   # NMS IoU threshold\n",
    "    'imgsz': 640,  # Image size for inference\n",
    "    'device': 0,   # GPU device (0 for first GPU, 'cpu' for CPU)\n",
    "    'verbose': False,\n",
    "}\n",
    "\n",
    "print(f\"üìÅ Output directory: {FEATURES_DIR}\")\n",
    "print(f\"üìä Models available: {[k for k, v in MODELS.items() if v.exists()]}\")\n",
    "print(f\"üìÖ Years to process: {YEARS}\")\n",
    "print(f\"‚öôÔ∏è  Device: {'GPU' if INFERENCE_CONFIG['device'] == 0 else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Location Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location categories\n",
    "LOCATION_CATEGORIES = {\n",
    "    'retail': [\n",
    "        'Mall_of_America', 'Westfield_Century_City', 'The_Grove_LA',\n",
    "        'South_Coast_Plaza', 'Tysons_Corner_Center', 'King_of_Prussia',\n",
    "        'Roosevelt_Field', 'Westfield_London', 'Bluewater', 'Trafford_Centre',\n",
    "        'Galeries_Lafayette', 'La_Maquinista', 'Centro_Oberhausen',\n",
    "        'Pacific_Mall_Delhi', 'Select_Citywalk', 'Mall_of_Asia_Manila'\n",
    "    ],\n",
    "    'ports': [\n",
    "        'Port_of_Los_Angeles', 'Port_of_Long_Beach', 'Port_of_New_York_New_Jersey',\n",
    "        'Port_of_Savannah', 'Port_of_Houston', 'Port_of_Rotterdam',\n",
    "        'Port_of_Antwerp', 'Port_of_Hamburg', 'Port_of_Valencia',\n",
    "        'Port_of_Shanghai', 'Port_of_Ningbo', 'Port_of_Singapore',\n",
    "        'Port_of_Busan', 'Port_of_Hong_Kong', 'Port_of_Durban',\n",
    "        'Port_of_Mombasa', 'Port_of_Lagos', 'Port_of_Jebel_Ali',\n",
    "        'Port_of_Salalah'\n",
    "    ],\n",
    "    'industrial': [\n",
    "        'Shenzhen_Electronics', 'Suzhou_Industrial_Park', 'Pune_Hinjawadi',\n",
    "        'Detroit_Auto', 'Tijuana_Manufacturing'\n",
    "    ],\n",
    "    'city': [\n",
    "        'Los_Angeles', 'New_York_City', 'Chicago', 'London', 'Paris',\n",
    "        'Tokyo', 'Beijing', 'Mumbai', 'Johannesburg', 'Sao_Paulo'\n",
    "    ]\n",
    "}\n",
    "\n",
    "for category, locations in LOCATION_CATEGORIES.items():\n",
    "    print(f\"{category.upper()}: {len(locations)} locations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path: Path, model_name: str) -> YOLO:\n",
    "    \"\"\"Load a YOLO model.\"\"\"\n",
    "    if not model_path.exists():\n",
    "        print(f\"‚ö†Ô∏è  Model not found: {model_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üì• Loading {model_name} model...\")\n",
    "    model = YOLO(str(model_path))\n",
    "    print(f\"   ‚úÖ {model_name.upper()} model loaded\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def find_images(location: str, year: int) -> List[Path]:\n",
    "    \"\"\"Find all imagery files for a location and year.\"\"\"\n",
    "    images = []\n",
    "    \n",
    "    # Check NAIP (US locations only, high-res)\n",
    "    naip_path = RAW_SATELLITE / \"naip\" / str(year)\n",
    "    if naip_path.exists():\n",
    "        naip_files = list(naip_path.glob(f\"{location}_naip_{year}.tif\"))\n",
    "        images.extend(naip_files)\n",
    "    \n",
    "    # Check Sentinel-2 (all locations, 10m resolution)\n",
    "    sentinel_path = RAW_SATELLITE / \"sentinel-2-l2a\" / str(year)\n",
    "    if sentinel_path.exists():\n",
    "        sentinel_files = list(sentinel_path.glob(f\"{location}_sentinel-2-l2a_{year}.tif\"))\n",
    "        images.extend(sentinel_files)\n",
    "    \n",
    "    return images\n",
    "\n",
    "\n",
    "def process_image(image_path: Path, model: YOLO, config: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Run inference on a single image and return detections as DataFrame.\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(str(image_path))\n",
    "        if img is None:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        results = model(\n",
    "            img,\n",
    "            conf=config['conf'],\n",
    "            iou=config['iou'],\n",
    "            imgsz=config['imgsz'],\n",
    "            device=config['device'],\n",
    "            verbose=config['verbose']\n",
    "        )[0]\n",
    "        \n",
    "        if len(results.boxes) == 0:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        detections = []\n",
    "        for box in results.boxes:\n",
    "            detection = {\n",
    "                'class_id': int(box.cls.item()),\n",
    "                'class_name': results.names[int(box.cls.item())],\n",
    "                'confidence': float(box.conf.item()),\n",
    "                'x1': float(box.xyxy[0][0]),\n",
    "                'y1': float(box.xyxy[0][1]),\n",
    "                'x2': float(box.xyxy[0][2]),\n",
    "                'y2': float(box.xyxy[0][3]),\n",
    "            }\n",
    "            detections.append(detection)\n",
    "        \n",
    "        return pd.DataFrame(detections)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def aggregate_detections(\n",
    "    detections: pd.DataFrame,\n",
    "    location: str,\n",
    "    year: int,\n",
    "    month: int,\n",
    "    activity_type: str\n",
    ") -> Dict:\n",
    "    \"\"\"Aggregate raw detections into activity metrics.\"\"\"\n",
    "    metric = {\n",
    "        'location': location,\n",
    "        'year': year,\n",
    "        'month': month,\n",
    "        'date': f\"{year}-{month:02d}-15\",\n",
    "        'activity_type': activity_type,\n",
    "        'total_objects': len(detections) if not detections.empty else 0,\n",
    "    }\n",
    "    \n",
    "    # Class-specific counts\n",
    "    if not detections.empty:\n",
    "        class_counts = detections['class_name'].value_counts().to_dict()\n",
    "    else:\n",
    "        class_counts = {}\n",
    "    \n",
    "    for class_name in CLASS_NAMES.get(activity_type, []):\n",
    "        metric[f'{class_name}_count'] = class_counts.get(class_name, 0)\n",
    "    \n",
    "    # Activity-specific metrics\n",
    "    if activity_type == 'retail':\n",
    "        metric['car_density'] = metric.get('car_count', 0)\n",
    "        metric['parking_activity_index'] = metric['car_density'] + metric.get('equipment_count', 0) * 0.5\n",
    "    \n",
    "    elif activity_type == 'ports':\n",
    "        ships = metric.get('ship_count', 0)\n",
    "        large_vehicles = metric.get('large-vehicle_count', 0)\n",
    "        small_vehicles = metric.get('small-vehicle_count', 0)\n",
    "        metric['congestion_index'] = ships * 2.0 + large_vehicles * 1.0 + small_vehicles * 0.5\n",
    "        metric['port_activity_index'] = ships + large_vehicles + small_vehicles + metric.get('storage-tank_count', 0)\n",
    "    \n",
    "    elif activity_type == 'city':\n",
    "        cars = metric.get('car_count', 0)\n",
    "        trucks = metric.get('truck_count', 0)\n",
    "        metric['vehicle_density'] = cars + trucks\n",
    "        metric['traffic_index'] = cars + trucks * 1.5\n",
    "        metric['logistics_activity'] = trucks + metric.get('warehouse_count', 0)\n",
    "    \n",
    "    elif activity_type == 'industrial':\n",
    "        trucks = metric.get('truck_count', 0)\n",
    "        warehouses = metric.get('warehouse_count', 0)\n",
    "        metric['industrial_activity_index'] = trucks * 2.0 + warehouses * 1.0\n",
    "        metric['logistics_intensity'] = trucks\n",
    "    \n",
    "    return metric\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Main Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_activity(\n",
    "    activity_type: str,\n",
    "    model: YOLO,\n",
    "    locations: List[str],\n",
    "    years: List[int]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Run inference for all locations and years for a specific activity type.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üöÄ Running Inference: {activity_type.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Locations: {len(locations)}\")\n",
    "    print(f\"Years: {years}\")\n",
    "    print(f\"Total combinations: {len(locations) * len(years)}\")\n",
    "    \n",
    "    all_metrics = []\n",
    "    \n",
    "    total_tasks = len(locations) * len(years)\n",
    "    with tqdm(total=total_tasks, desc=f\"{activity_type.upper()}\", unit=\"img\") as pbar:\n",
    "        for location in locations:\n",
    "            for year in years:\n",
    "                images = find_images(location, year)\n",
    "                \n",
    "                if not images:\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                for image_path in images:\n",
    "                    detections = process_image(image_path, model, INFERENCE_CONFIG)\n",
    "                    month = 6  # Mid-year\n",
    "                    metric = aggregate_detections(detections, location, year, month, activity_type)\n",
    "                    all_metrics.append(metric)\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    df = pd.DataFrame(all_metrics)\n",
    "    \n",
    "    if not df.empty:\n",
    "        print(f\"\\n‚úÖ {activity_type.upper()} Inference Complete!\")\n",
    "        print(f\"   Records: {len(df)}\")\n",
    "        print(f\"   Date range: {df['year'].min()}-{df['year'].max()}\")\n",
    "        print(f\"   Locations: {df['location'].nunique()}\")\n",
    "        print(f\"   Total objects detected: {df['total_objects'].sum():,}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Main inference function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üì• LOADING MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "models = {}\n",
    "for activity_type, model_path in MODELS.items():\n",
    "    model = load_model(model_path, activity_type)\n",
    "    if model is not None:\n",
    "        models[activity_type] = model\n",
    "\n",
    "if not models:\n",
    "    print(\"\\n‚ùå No models found! Please train models first.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Loaded {len(models)} models: {list(models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Inference\n",
    "\n",
    "### 7.1 Retail Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'retail' in models:\n",
    "    retail_df = run_inference_for_activity(\n",
    "        'retail',\n",
    "        models['retail'],\n",
    "        LOCATION_CATEGORIES['retail'],\n",
    "        YEARS\n",
    "    )\n",
    "    \n",
    "    # Save\n",
    "    output_path = FEATURES_DIR / \"retail_activity.csv\"\n",
    "    retail_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nüíæ Saved: {output_path}\")\n",
    "    \n",
    "    # Preview\n",
    "    display(retail_df.head(10))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Retail model not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Port Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ports' in models:\n",
    "    ports_df = run_inference_for_activity(\n",
    "        'ports',\n",
    "        models['ports'],\n",
    "        LOCATION_CATEGORIES['ports'],\n",
    "        YEARS\n",
    "    )\n",
    "    \n",
    "    # Save\n",
    "    output_path = FEATURES_DIR / \"port_activity.csv\"\n",
    "    ports_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nüíæ Saved: {output_path}\")\n",
    "    \n",
    "    # Preview\n",
    "    display(ports_df.head(10))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Ports model not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 City Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'city' in models:\n",
    "    city_df = run_inference_for_activity(\n",
    "        'city',\n",
    "        models['city'],\n",
    "        LOCATION_CATEGORIES['city'],\n",
    "        YEARS\n",
    "    )\n",
    "    \n",
    "    # Save\n",
    "    output_path = FEATURES_DIR / \"city_activity.csv\"\n",
    "    city_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nüíæ Saved: {output_path}\")\n",
    "    \n",
    "    # Preview\n",
    "    display(city_df.head(10))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  City model not available (may still be training)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Industrial Activity\n",
    "\n",
    "Uses city model (trucks + warehouses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'city' in models:\n",
    "    industrial_df = run_inference_for_activity(\n",
    "        'industrial',\n",
    "        models['city'],  # Use city model\n",
    "        LOCATION_CATEGORIES['industrial'],\n",
    "        YEARS\n",
    "    )\n",
    "    \n",
    "    # Save\n",
    "    output_path = FEATURES_DIR / \"industrial_activity.csv\"\n",
    "    industrial_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nüíæ Saved: {output_path}\")\n",
    "    \n",
    "    # Preview\n",
    "    display(industrial_df.head(10))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  City model not available for industrial inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ INFERENCE COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\nResults saved to: {FEATURES_DIR}\")\n",
    "\n",
    "# List saved files\n",
    "saved_files = list(FEATURES_DIR.glob(\"*_activity.csv\"))\n",
    "print(f\"\\nSaved files:\")\n",
    "for file in saved_files:\n",
    "    size_kb = file.stat().st_size / 1024\n",
    "    print(f\"  ‚úÖ {file.name} ({size_kb:.1f} KB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä NEXT STEPS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"1. Review output CSV files\")\n",
    "print(\"2. Run Analyze_Activity_Metrics.ipynb\")\n",
    "print(\"3. Download economic indicators (FRED)\")\n",
    "print(\"4. Train forecasting models\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
