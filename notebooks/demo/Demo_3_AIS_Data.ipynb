{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 3: AIS Maritime Data\n",
    "\n",
    "**Processing ship tracking data from NOAA**\n",
    "\n",
    "## What is AIS?\n",
    "- **Automatic Identification System** - GPS tracking for ships\n",
    "- Ships broadcast position, speed, heading, vessel type\n",
    "- NOAA collects and provides historical data\n",
    "\n",
    "## What We're Doing:\n",
    "- Load AIS data for Port of LA region\n",
    "- Extract ship counts and vessel types\n",
    "- Visualize maritime traffic patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Works both locally and in SageMaker\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Install dependencies in SageMaker\n",
    "IS_SAGEMAKER = os.path.exists('/home/ec2-user/SageMaker') or os.environ.get('SM_MODEL_DIR') is not None\n",
    "\n",
    "if IS_SAGEMAKER:\n",
    " print(' Installing dependencies...')\n",
    " import subprocess\n",
    " subprocess.run(['pip', 'install', 'ultralytics', 'opencv-python-headless', '-q'], check=True)\n",
    " print(' Dependencies installed')\n",
    "\n",
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# YOLO import\n",
    "try:\n",
    " from ultralytics import YOLO\n",
    " YOLO_AVAILABLE = True\n",
    "except ImportError:\n",
    " YOLO_AVAILABLE = False\n",
    " print(' YOLO not available - run: pip install ultralytics')\n",
    "\n",
    "# Environment detection\n",
    "if IS_SAGEMAKER:\n",
    " PROJECT_ROOT = Path('/home/ec2-user/SageMaker/Real-Time-Economic-Forecasting')\n",
    " USE_S3 = True\n",
    " print(' Running in AWS SageMaker')\n",
    "else:\n",
    " PROJECT_ROOT = Path.cwd().parent.parent\n",
    " USE_S3 = False\n",
    " print(' Running locally')\n",
    "\n",
    "# ===========================================\n",
    "# S3 BUCKET CONFIGURATION (ACTUAL STRUCTURE)\n",
    "# ===========================================\n",
    "S3_RAW = 'economic-forecast-raw'\n",
    "S3_MODELS = 'economic-forecast-models'\n",
    "S3_PROCESSED = 'economic-forecast-processed'\n",
    "\n",
    "# S3 Paths (matching actual bucket structure)\n",
    "S3_PATHS = {\n",
    " 'satellite': f's3://{S3_RAW}/satellite/google_earth',\n",
    " 'port_la_images': f's3://{S3_RAW}/satellite/google_earth/Port_of_LA',\n",
    " 'mall_images': f's3://{S3_RAW}/satellite/google_earth/Mall_of_america',\n",
    " 'models': f's3://{S3_MODELS}/yolo',\n",
    " 'port_model': f's3://{S3_MODELS}/yolo/ports/best.pt',\n",
    " 'retail_model': f's3://{S3_MODELS}/yolo/retail/best.pt',\n",
    " 'city_model': f's3://{S3_MODELS}/yolo/city/best.pt',\n",
    " 'ais': f's3://{S3_PROCESSED}/ais',\n",
    " 'ais_la': f's3://{S3_PROCESSED}/ais/Port_of_LA_ais_features.csv',\n",
    " 'detections': f's3://{S3_PROCESSED}/detections',\n",
    " 'news': f's3://{S3_RAW}/news/sentiment/data',\n",
    "}\n",
    "\n",
    "# Local paths\n",
    "LOCAL_PATHS = {\n",
    " 'satellite': PROJECT_ROOT / 'data' / 'raw' / 'satellite' / 'google_earth',\n",
    " 'port_la_images': PROJECT_ROOT / 'data' / 'raw' / 'satellite' / 'google_earth' / 'Port_of_LA',\n",
    " 'mall_images': PROJECT_ROOT / 'data' / 'raw' / 'satellite' / 'google_earth' / 'Mall_of_america',\n",
    " 'models': PROJECT_ROOT / 'data' / 'models' / 'satellite',\n",
    " 'port_model': PROJECT_ROOT / 'data' / 'models' / 'satellite' / 'ports_dota_yolo11_20251127_013205' / 'weights' / 'best.pt',\n",
    " 'retail_model': PROJECT_ROOT / 'data' / 'models' / 'satellite' / 'retail_yolo11_20251126_150811' / 'weights' / 'best.pt',\n",
    " 'ais': PROJECT_ROOT / 'data' / 'processed' / 'ais',\n",
    " 'ais_la': PROJECT_ROOT / 'data' / 'processed' / 'ais' / 'Port_of_LA_ais_features.csv',\n",
    " 'detections': PROJECT_ROOT / 'results' / 'annotations',\n",
    "}\n",
    "\n",
    "def get_path(key):\n",
    " '''Get path - S3 or local based on environment.'''\n",
    " if USE_S3:\n",
    "  return S3_PATHS.get(key, S3_PATHS.get('satellite'))\n",
    " else:\n",
    "  return LOCAL_PATHS.get(key, LOCAL_PATHS.get('satellite'))\n",
    "\n",
    "def download_model(model_type='port'):\n",
    " '''Download model from S3 to local temp for inference.'''\n",
    " if not USE_S3:\n",
    "  # Return local path\n",
    "  if model_type == 'port':\n",
    "   return LOCAL_PATHS['port_model']\n",
    "  elif model_type == 'retail':\n",
    "   return LOCAL_PATHS['retail_model']\n",
    "  return None\n",
    " \n",
    " import boto3\n",
    " import tempfile\n",
    " \n",
    " s3 = boto3.client('s3')\n",
    " \n",
    " model_keys = {\n",
    "  'port': 'yolo/ports/best.pt',\n",
    "  'retail': 'yolo/retail/best.pt',\n",
    "  'city': 'yolo/city/best.pt',\n",
    " }\n",
    " \n",
    " key = model_keys.get(model_type)\n",
    " if not key:\n",
    "  print(f' Unknown model type: {model_type}')\n",
    "  return None\n",
    " \n",
    " local_path = Path(tempfile.gettempdir()) / f'{model_type}_best.pt'\n",
    " \n",
    " if not local_path.exists():\n",
    "  print(f' Downloading {model_type} model from S3...')\n",
    "  s3.download_file(S3_MODELS, key, str(local_path))\n",
    "  print(f' Model saved to {local_path}')\n",
    " else:\n",
    "  print(f' Using cached model: {local_path}')\n",
    " \n",
    " return local_path\n",
    "\n",
    "def list_s3_images(prefix):\n",
    " '''List images in S3 bucket.'''\n",
    " import boto3\n",
    " s3 = boto3.client('s3')\n",
    " \n",
    " # Parse bucket and prefix from s3:// path\n",
    " if prefix.startswith('s3://'):\n",
    "  parts = prefix.replace('s3://', '').split('/', 1)\n",
    "  bucket = parts[0]\n",
    "  prefix = parts[1] if len(parts) > 1 else ''\n",
    " else:\n",
    "  bucket = S3_RAW\n",
    " \n",
    " response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    " \n",
    " images = []\n",
    " for obj in response.get('Contents', []):\n",
    "  key = obj['Key']\n",
    "  if key.endswith(('.jpg', '.jpeg', '.png', '.tif')):\n",
    "   images.append(f's3://{bucket}/{key}')\n",
    " \n",
    " return images\n",
    "\n",
    "def download_image(s3_path, local_dir='/tmp'):\n",
    " '''Download single image from S3.'''\n",
    " import boto3\n",
    " s3 = boto3.client('s3')\n",
    " \n",
    " parts = s3_path.replace('s3://', '').split('/', 1)\n",
    " bucket = parts[0]\n",
    " key = parts[1]\n",
    " \n",
    " filename = key.split('/')[-1]\n",
    " local_path = Path(local_dir) / filename\n",
    " \n",
    " s3.download_file(bucket, key, str(local_path))\n",
    " return local_path\n",
    "\n",
    "print(f' Setup complete | S3: {USE_S3} | YOLO: {YOLO_AVAILABLE}')\n",
    "print(f' Project: {PROJECT_ROOT}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Understanding AIS Data\n",
    "\n",
    "```\n",
    "Ship broadcasts every few seconds:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ MMSI: 123456789 (unique ship ID)    â”‚\n",
    "â”‚ LAT: 33.7234, LON: -118.2654     â”‚\n",
    "â”‚ SOG: 12.5 knots (speed over ground)    â”‚\n",
    "â”‚ COG: 275Â° (course over ground)     â”‚\n",
    "â”‚ VesselType: 70 (cargo ship)      â”‚\n",
    "â”‚ VesselName: \"EVER GIVEN\"      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIS Vessel Type Codes\n",
    "print(\"ðŸ“‹ AIS VESSEL TYPE CODES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "vessel_types = {\n",
    " '70-79': 'Cargo vessels',\n",
    " '80-89': 'Tankers',\n",
    " '60-69': 'Passenger vessels',\n",
    " '30': 'Fishing vessels',\n",
    " '31-32': 'Tug boats',\n",
    " '36-37': 'Sailing vessels',\n",
    "}\n",
    "\n",
    "for code, desc in vessel_types.items():\n",
    " print(f\" {code}: {desc}\")\n",
    "\n",
    "print(\"\\n Cargo (70-79) and Tankers (80-89) are key economic indicators!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load AIS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available AIS data\n",
    "ais_processed_dir = PROJECT_ROOT / 'data' / 'processed' / 'ais'\n",
    "ais_raw_dir = PROJECT_ROOT / 'data' / 'raw' / 'ais' / 'noaa_daily'\n",
    "\n",
    "print(\"AVAILABLE AIS DATA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check processed data first (ready to use)\n",
    "print(\"\\nProcessed AIS Data:\")\n",
    "if ais_processed_dir.exists():\n",
    "    for f in sorted(ais_processed_dir.glob('*.csv')):\n",
    "        size = f.stat().st_size / 1024\n",
    "        print(f\"  {f.name} ({size:.1f} KB)\")\n",
    "else:\n",
    "    print(\"  No processed data found\")\n",
    "\n",
    "# Check raw data\n",
    "print(\"\\nRaw AIS Data (zip files):\")\n",
    "if ais_raw_dir.exists():\n",
    "    for year_dir in sorted(ais_raw_dir.iterdir()):\n",
    "        if year_dir.is_dir():\n",
    "            files = list(year_dir.glob('*.zip'))\n",
    "            if files:\n",
    "                total_size = sum(f.stat().st_size for f in files) / (1024*1024)\n",
    "                print(f\"  {year_dir.name}: {len(files)} files ({total_size:.1f} MB)\")\n",
    "else:\n",
    "    print(\"  No raw data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Port of LA bounding box\n",
    "PORT_LA_BOUNDS = {\n",
    " 'min_lat': 33.65,\n",
    " 'max_lat': 33.85,\n",
    " 'min_lon': -118.35,\n",
    " 'max_lon': -118.15\n",
    "}\n",
    "\n",
    "print(\"ðŸ“ PORT OF LA BOUNDING BOX\")\n",
    "print(\"=\"*50)\n",
    "print(f\" Latitude: {PORT_LA_BOUNDS['min_lat']}Â° to {PORT_LA_BOUNDS['max_lat']}Â°\")\n",
    "print(f\" Longitude: {PORT_LA_BOUNDS['min_lon']}Â° to {PORT_LA_BOUNDS['max_lon']}Â°\")\n",
    "\n",
    "# Visualize on a simple map\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Draw bounding box\n",
    "from matplotlib.patches import Rectangle\n",
    "rect = Rectangle(\n",
    " (PORT_LA_BOUNDS['min_lon'], PORT_LA_BOUNDS['min_lat']),\n",
    " PORT_LA_BOUNDS['max_lon'] - PORT_LA_BOUNDS['min_lon'],\n",
    " PORT_LA_BOUNDS['max_lat'] - PORT_LA_BOUNDS['min_lat'],\n",
    " fill=True, facecolor='lightblue', edgecolor='blue', linewidth=2, alpha=0.5\n",
    ")\n",
    "ax.add_patch(rect)\n",
    "\n",
    "# Add port marker\n",
    "ax.plot(-118.25, 33.75, 'r*', markersize=20, label='Port of LA')\n",
    "\n",
    "ax.set_xlim(-118.5, -118.0)\n",
    "ax.set_ylim(33.5, 34.0)\n",
    "ax.set_xlabel('Longitude', fontsize=12)\n",
    "ax.set_ylabel('Latitude', fontsize=12)\n",
    "ax.set_title('ðŸ—ºï¸ Port of LA - AIS Capture Area', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Process AIS Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ACTUAL processed AIS data\n",
    "import zipfile\n",
    "\n",
    "def load_ais_data():\n",
    "    \"\"\"Load AIS data - processed CSV or from zip file.\"\"\"\n",
    "    \n",
    "    # First try processed data (preferred)\n",
    "    processed_files = {\n",
    "        'daily': PROJECT_ROOT / 'data' / 'processed' / 'ais' / 'Port_of_LA_ais_daily.csv',\n",
    "        'features': PROJECT_ROOT / 'data' / 'processed' / 'ais' / 'Port_of_LA_ais_features.csv',\n",
    "    }\n",
    "    \n",
    "    if processed_files['daily'].exists():\n",
    "        print(f\"Loading processed data: {processed_files['daily'].name}\")\n",
    "        df = pd.read_csv(processed_files['daily'])\n",
    "        print(f\"  Loaded {len(df):,} daily records\")\n",
    "        return df, 'daily'\n",
    "    \n",
    "    if processed_files['features'].exists():\n",
    "        print(f\"Loading features data: {processed_files['features'].name}\")\n",
    "        df = pd.read_csv(processed_files['features'])\n",
    "        print(f\"  Loaded {len(df):,} feature records\")\n",
    "        return df, 'features'\n",
    "    \n",
    "    # Try raw zip files\n",
    "    ais_files = list((PROJECT_ROOT / 'data' / 'raw' / 'ais' / 'noaa_daily').rglob('*.zip'))\n",
    "    \n",
    "    if ais_files:\n",
    "        zip_path = ais_files[0]\n",
    "        print(f\"Loading raw data: {zip_path.name}\")\n",
    "        \n",
    "        with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "            csv_name = [f for f in z.namelist() if f.endswith('.csv')][0]\n",
    "            with z.open(csv_name) as f:\n",
    "                df = pd.read_csv(f, nrows=100000)\n",
    "        \n",
    "        # Filter to Port of LA\n",
    "        df_filtered = df[\n",
    "            (df['LAT'] >= PORT_LA_BOUNDS['min_lat']) &\n",
    "            (df['LAT'] <= PORT_LA_BOUNDS['max_lat']) &\n",
    "            (df['LON'] >= PORT_LA_BOUNDS['min_lon']) &\n",
    "            (df['LON'] <= PORT_LA_BOUNDS['max_lon'])\n",
    "        ]\n",
    "        \n",
    "        if len(df_filtered) > 0:\n",
    "            return df_filtered, 'raw'\n",
    "    \n",
    "    # Create sample if nothing found\n",
    "    print(\"Creating sample AIS data for demo...\")\n",
    "    np.random.seed(42)\n",
    "    n_records = 365\n",
    "    \n",
    "    sample_df = pd.DataFrame({\n",
    "        'date': pd.date_range('2024-01-01', periods=n_records, freq='D'),\n",
    "        'unique_ships': np.random.randint(150, 300, n_records),\n",
    "        'cargo_ships': np.random.randint(80, 150, n_records),\n",
    "        'tanker_ships': np.random.randint(30, 60, n_records),\n",
    "        'avg_speed': np.random.uniform(8, 12, n_records),\n",
    "    })\n",
    "    \n",
    "    return sample_df, 'sample'\n",
    "\n",
    "ais_df, data_type = load_ais_data()\n",
    "print(f\"\\nData type: {data_type}\")\n",
    "print(f\"Columns: {list(ais_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show AIS data\n",
    "print(\"AIS DATA\")\n",
    "print(\"=\"*60)\n",
    "display(ais_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Analyze Ship Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze ship traffic from ACTUAL data\n",
    "print(\"SHIP TRAFFIC ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if 'unique_ships' in ais_df.columns:\n",
    "    # Using processed daily data\n",
    "    print(\"\\nYearly Ship Counts at Port of LA:\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    for _, row in ais_df.iterrows():\n",
    "        date = row['date'] if isinstance(row['date'], str) else str(row['date'])[:10]\n",
    "        year = date[:4]\n",
    "        print(f\"  {date}: {row['unique_ships']} total ships\")\n",
    "        print(f\"           Cargo: {row['cargo_ships']}, Tankers: {row['tanker_ships']}, Passenger: {row['passenger_ships']}\")\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_ships = ais_df['unique_ships'].mean()\n",
    "    avg_cargo = ais_df['cargo_ships'].mean()\n",
    "    avg_tanker = ais_df['tanker_ships'].mean()\n",
    "    \n",
    "    print(f\"\\nAverages (2018-2024):\")\n",
    "    print(f\"  Total ships/day: {avg_ships:.0f}\")\n",
    "    print(f\"  Cargo ships/day: {avg_cargo:.0f}\")\n",
    "    print(f\"  Tanker ships/day: {avg_tanker:.0f}\")\n",
    "else:\n",
    "    # Raw data with vessel categories\n",
    "    ship_counts = ais_df.groupby('vessel_category')['MMSI'].nunique().sort_values(ascending=False)\n",
    "    for cat, count in ship_counts.items():\n",
    "        print(f\"  {cat}: {count} ships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ACTUAL vessel distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "if 'unique_ships' in ais_df.columns:\n",
    "    # Using processed daily data\n",
    "    years = [str(d)[:4] for d in ais_df['date']]\n",
    "    \n",
    "    # Bar chart of total ships by year\n",
    "    ax1 = axes[0]\n",
    "    colors = plt.cm.Blues(np.linspace(0.4, 0.9, len(ais_df)))\n",
    "    bars = ax1.bar(years, ais_df['unique_ships'], color=colors, edgecolor='black')\n",
    "    ax1.set_xlabel('Year', fontsize=12)\n",
    "    ax1.set_ylabel('Unique Ships', fontsize=12)\n",
    "    ax1.set_title('Total Ships at Port of LA', fontsize=14, fontweight='bold')\n",
    "    for bar, val in zip(bars, ais_df['unique_ships']):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 3, str(val), \n",
    "                ha='center', fontweight='bold')\n",
    "    \n",
    "    # Stacked bar of vessel types\n",
    "    ax2 = axes[1]\n",
    "    x = np.arange(len(years))\n",
    "    width = 0.6\n",
    "    \n",
    "    ax2.bar(x, ais_df['cargo_ships'], width, label='Cargo', color='#2ecc71')\n",
    "    ax2.bar(x, ais_df['tanker_ships'], width, bottom=ais_df['cargo_ships'], label='Tanker', color='#3498db')\n",
    "    ax2.bar(x, ais_df['passenger_ships'], width, \n",
    "            bottom=ais_df['cargo_ships'] + ais_df['tanker_ships'], label='Passenger', color='#e74c3c')\n",
    "    \n",
    "    ax2.set_xlabel('Year', fontsize=12)\n",
    "    ax2.set_ylabel('Number of Ships', fontsize=12)\n",
    "    ax2.set_title('Ships by Type', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(years)\n",
    "    ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# COVID impact analysis\n",
    "if 'unique_ships' in ais_df.columns:\n",
    "    print(\"\\nCOVID-19 Impact Analysis:\")\n",
    "    print(\"-\"*40)\n",
    "    pre_covid = ais_df[ais_df['date'].astype(str) < '2020']['unique_ships'].mean()\n",
    "    covid_2020 = ais_df[ais_df['date'].astype(str).str.startswith('2020')]['unique_ships'].values\n",
    "    post_covid = ais_df[ais_df['date'].astype(str) > '2021']['unique_ships'].mean()\n",
    "    \n",
    "    if len(covid_2020) > 0:\n",
    "        print(f\"  Pre-COVID (2018-2019): {pre_covid:.0f} ships/day\")\n",
    "        print(f\"  During COVID (2020):   {covid_2020[0]} ships/day\")\n",
    "        print(f\"  Post-COVID (2022-2024): {post_covid:.0f} ships/day\")\n",
    "        print(f\"\\n  COVID drop: {((pre_covid - covid_2020[0])/pre_covid)*100:.1f}%\")\n",
    "        print(f\"  Recovery: +{((post_covid - covid_2020[0])/covid_2020[0])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ship Positions Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ship traffic trends over time\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "if 'unique_ships' in ais_df.columns:\n",
    "    years = [str(d)[:4] for d in ais_df['date']]\n",
    "    \n",
    "    ax.plot(years, ais_df['unique_ships'], 'b-o', linewidth=2, markersize=10, label='Total Ships')\n",
    "    ax.plot(years, ais_df['cargo_ships'], 'g--s', linewidth=2, markersize=8, label='Cargo Ships')\n",
    "    ax.plot(years, ais_df['tanker_ships'], 'r--^', linewidth=2, markersize=8, label='Tankers')\n",
    "    \n",
    "    # Highlight COVID year\n",
    "    covid_idx = [i for i, y in enumerate(years) if y == '2020']\n",
    "    if covid_idx:\n",
    "        ax.axvspan(covid_idx[0]-0.3, covid_idx[0]+0.3, alpha=0.2, color='red', label='COVID-19')\n",
    "    \n",
    "    ax.set_xlabel('Year', fontsize=12)\n",
    "    ax.set_ylabel('Number of Ships', fontsize=12)\n",
    "    ax.set_title('Port of LA - Ship Traffic Trends (2018-2024)', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Economic Metrics from AIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate economic indicators from ACTUAL data\n",
    "print(\"ECONOMIC INDICATORS FROM AIS DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'unique_ships' in ais_df.columns:\n",
    "    # Calculate metrics\n",
    "    total_avg = ais_df['unique_ships'].mean()\n",
    "    cargo_avg = ais_df['cargo_ships'].mean()\n",
    "    tanker_avg = ais_df['tanker_ships'].mean()\n",
    "    \n",
    "    # Trade activity index\n",
    "    trade_ships = ais_df['cargo_ships'] + ais_df['tanker_ships']\n",
    "    trade_ratio = (trade_ships / ais_df['unique_ships'] * 100).mean()\n",
    "    \n",
    "    # Year-over-year growth\n",
    "    if len(ais_df) > 1:\n",
    "        yoy_growth = ((ais_df['unique_ships'].iloc[-1] - ais_df['unique_ships'].iloc[0]) / \n",
    "                      ais_df['unique_ships'].iloc[0] * 100)\n",
    "    else:\n",
    "        yoy_growth = 0\n",
    "    \n",
    "    print(f\"\\nKey Metrics (2018-2024):\")\n",
    "    print(f\"  Average ships/day:     {total_avg:.0f}\")\n",
    "    print(f\"  Average cargo ships:   {cargo_avg:.0f}\")\n",
    "    print(f\"  Average tankers:       {tanker_avg:.0f}\")\n",
    "    print(f\"  Trade Activity Ratio:  {trade_ratio:.1f}%\")\n",
    "    print(f\"  Growth (2018â†’2024):    {yoy_growth:+.1f}%\")\n",
    "    \n",
    "    print(f\"\\nLatest Data ({ais_df['date'].iloc[-1]}):\")\n",
    "    latest = ais_df.iloc[-1]\n",
    "    print(f\"  Total ships:    {latest['unique_ships']}\")\n",
    "    print(f\"  Cargo ships:    {latest['cargo_ships']}\")\n",
    "    print(f\"  Tanker ships:   {latest['tanker_ships']}\")\n",
    "    print(f\"  Passenger:      {latest['passenger_ships']}\")\n",
    "    \n",
    "    print(f\"\\nINSIGHT:\")\n",
    "    print(f\"  Port traffic recovered {yoy_growth:.0f}% since 2018\")\n",
    "    print(f\"  Cargo ships represent {cargo_avg/total_avg*100:.0f}% of trade activity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Data Source:\n",
    "- **NOAA AIS Data**: Ship tracking from 2018-2024\n",
    "- **Port of LA**: Major US trade gateway\n",
    "- **7 sample days**: One per year for trend analysis\n",
    "\n",
    "### Key Findings:\n",
    "| Year | Total Ships | Cargo | Tankers |\n",
    "|------|-------------|-------|---------|\n",
    "| 2018 | 234 | 37 | 12 |\n",
    "| 2019 | 239 | 27 | 15 |\n",
    "| 2020 | 218 | 21 | 7 | (COVID drop)\n",
    "| 2021 | 275 | 57 | 18 |\n",
    "| 2022 | 257 | 59 | 15 |\n",
    "| 2023 | 286 | 44 | 15 |\n",
    "| 2024 | 287 | 42 | 15 |\n",
    "\n",
    "### Economic Insights:\n",
    "1. **COVID-19 Impact**: 7% drop in 2020\n",
    "2. **Recovery**: 32% increase from 2020 to 2024\n",
    "3. **Trade Activity**: Cargo + Tankers = key economic indicator\n",
    "\n",
    "### Next Step:\n",
    "**Demo 4**: Fuse satellite detections with AIS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\" Demo 3 Complete: AIS Data Processing\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n Next: Demo_4_Data_Fusion.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
